---
published: true
layout: single
title: RDD
categories:
  - SPARK
tags:
  - RDD

toc: true
toc_sticky: true

---

## Resilient Distributed Dataset 
탄력적인 분산 데이터셋같은 느낌

코드에선 SparkContext를 RDD 객체로 사용할 수 있다.  

### RDD의 특징
1. 추상화
   데이터는 클러스터에 흩어져있지만 하나의 파일인 것 처럼 사용이 가능하다.  
	
	![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220825150742.png)

2. 탄력적(Resilient)이고 불변(immutable)하는 성질이 있다.
   - immutable
     RDD가 정해진 처리에따라 변환할때 변경되는게 아닌 새롭게 만들어져 기존값이 그대로 존재하게된다.   
     ![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220825150949.png)  
	- Resilient
	  RDD의 변환 과정은 비순환 그래프(Acyclic Graph)로 그릴 수 있는데 과정중에 문제가 생길경우 쉽게 이전으로 돌아가 해결하고 다시 과정을 진행하게된다.	
3. Type-safe  
   컴파일시 Type을 판별할 수 있어 문제를 일찍 발견할 수 있다.
4. Unstructured/Structured Data를 동시에 다룰 수 있다.  
   ![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220825151303.png)  

5. Lazy  
   게으른 연산을 하는데 필요할 때까지 연산을 하지않는다.  
   ![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220825151408.png)  

Spark Operation은 Transform과 Action 두가지로 나누어진다.  

## 왜 RDD를 사용할까?  
- 유연하다  .
- 짧은 코드로 할 수 있는게 많다.  
- 개발할때 무엇보다는 어떻게에 대해 더 생각하게 한다
	- 게으른 연산 덕분에 데이터가 어떻게 변환될지 생각하게 된다.
	- 데이터가 지나갈 길을 닦는느낌

## Structure Data 와 RDD
Single Value RDD
- 텍스트에 등장하는 단어 수 세기 등
Key-Value RDD
- Key, Value 쌍을 갖는다
- 넷플릭스 드라마가 받은 평균 별점

## Key- value RDD에서 할 수 있는 것
### Reduction  함수
- reduceByKey() - 키값을 기준으로 태스크 처리
- groupByKey() - 키값을 기준으로 밸류를 묶음
- sortByKey() - 키값을 기준으로 정렬
- keys() - 키 값을 추출
- values() - 밸류값을 추출
### Join
- join
- rightOuterJoin
- LeftOuterJoin
- subtractByKey