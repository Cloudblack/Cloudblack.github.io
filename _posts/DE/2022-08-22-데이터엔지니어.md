---
published: true
layout: single
title: 데이터엔지니어를 시스템적으로 보자
categories:
  - DE
tags:
  - 데이터엔지니어

toc: true
toc_sticky: true

---

## 데이터의 전달 시스템으로 분류
1. 스트리밍
   - 실시간으로 데이터를 다른 저장소로 전달
   - 기존 데이터와 실시간 데이터를 같이 집계에서 서비스에서 즉각 활용
   - 기술스택 
     일반 서버 어플리케이션, Storm, Flink, Spark Streaming
2. 배치
   - 주기적으로 데이터를 백업, 다른 저장소로 이동
   - 주기적으로 데이터를 병합,삭제
   - 주기적으로 데이터를 가공
   - 기술 스택
     Quartz, Spring batch, Airflow, Spark

회사 혹은 서비스의상황에 따라 다르지만 각각의 장단점과 상황을 고려해 입력되는 데이터를 크게 스트리밍과 배치로볼 수 있다.  
나는 kinesis를 사용해본 경험이있는데 kinesis의 배치를 줄여서 스트리밍으로 생각하고있었는데 위에서 말하는 스트리밍에 대한 이해는 아직 부족하다
     
## 데이터의 가공 시스템
- ETL(Extract - transform -load)
- 원본 데이터를 가공해서 목적에 맞는 데이터를 생성
- 유효한 데이터를 판별 , drop/marking/transform
- 기술스택
  데이터의 전달에서 활용하는 도구들을 활용

이전에 해본 ETL (지금생각해보면 ETL스럽지도않음...)만을 DE로서 필요한 데이터의 가공이라고 생각했는데 ETL외에도 유효한 데이터를 판별해 데이터의 신뢰성을 올리는 작업 또한 아주 중요하다고 생각한다

## 데이터 분석 및 활용 시스템
- 분석가가 쉽게 활용할 수 있는 도구(SQL, Jupyter)를 이용해서 빠르게 데이터를 조회할 수 있는 시스템을 구축
- AI관련 엔지니어 또는 연구자가 활용할 수 있는 도구로 AI 로직을 태워볼 수 있는 환경 구축 (MLOps 관련)
- 빠르게 조회할 수 있는 환경을 구축
	- 빠르게 조회할 수 있는 데이터 저장소 API 서비스 개발
	- 빠르게 조회할 수 있는 데이터 베이스 데이터 적재
- 시스템, 서비스의 이상을 분석해서 판단
- 기술스택
  Elastic Search, Kibana, Hadoop, Hive, Jupyter, Spark, Presto, Druid

DE가 어떤목적으로 일을 하는지 결정된다고 볼 수 있다 이부분에서 해봤던것은 쿼리를 입력하면 API에서 제공해주는 것이니 빠르게 조회할 수 있는 환경을 구축 정도로 볼 수 있을 것이다.
아직 모르는부분이 많다
  
## 데이터 저장소
- DBA를 따로 두기 어려운 경우 DE에게 맡기는 경우
- DBA가 있어도 데이터 엔지니어가 데이터의 전달 가공 활용 시스템을 맡고 신뢰성을 보장할 수 있어야 한다.
- 데이터가 유실되지 않도록 보장
- 데이터 저장소를 안정적으로 이용할 수 있는 시스템
- 기술스택
  Elastic search, Hadoop

데이터의 신뢰성과 안정성이 무엇보다 중요하다.

  