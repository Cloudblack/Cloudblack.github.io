---
published: true
layout: single
title: 데이터엔지니어링?
categories:
  - DE
tags:
  - 데이터엔지니어

toc: true
toc_sticky: true

---

## 데이터의 전달 시스템으로 분류
1. 스트리밍 - 실시간
   - <mark style="background: #FF5582A6;">실시간으로 쏟아지는 데이터</mark> 를 <mark style="background: #FF5582A6;">계속 처리</mark> 하는 것
     - 이벤트가 생길때마다, 데이터가 들어올때마다 처리한다
     - 실시간성을 보장해야 할 때
     - 데이터가 여러 소스로부터 들어올 때
     - 데이터가 가끔 들어오거나 지속적으로 들어올때
     - 가벼운 처리를 할 때
	- 스트림 처리 플로우
		1. 데이터가 들어올떄마다 (ingest)
		2. 쿼리/처리 후 state를 업데이트
		3. DB에 담기  
		   ![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220823162856.png)  

   - 실시간으로 데이터를 다른 저장소로 전달
   - 기존 데이터와 실시간 데이터를 같이 집계에서 서비스에서 즉각 활용
   - 기술스택 
     일반 서버 어플리케이션, Storm, Flink, Spark Streaming
2. 배치 -  일괄
   - <mark style="background: #FF5582A6;">많은 양의 데이터</mark> 를 <mark style="background: #FF5582A6;">정해진 시간</mark> 에 <mark style="background: #FF5582A6;">한꺼번에 처리</mark> 하는것
	   - 한정된 대량의 데이터
	   - 특정시간
	   - 일괄처리
   - 주기적으로 데이터를 백업, 다른 저장소로 이동,데이터를 병합,삭제, 데이터를 가공등으로 전통적으로 쓰이는 데이터 처리 방법으로
		- 실시간성을 보장하지 않아도될 때
		- 데이터를 한꺼번에 처리할 수 있을때
		- 무거운 처리를 할때 (ex ML학습)
	- 배치 처리 플로우
	  1. 데이터를 모음
	  2. 데이터베이스에서 읽어서 처리
	  3. 다시 데이터베이스에 담기  
	  ![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220823162757.png)  

   - 기술 스택
     Quartz, Spring batch, Airflow, Spark

3. 마이크로 배치
   - 데이터를 조금씩 모아서 프로세싱하는 방식으로 batch 프로세싱을 잘게 쪼개 스트리밍을 흉내내는 방식


회사 혹은 서비스의상황에 따라 다르지만 각각의 장단점과 상황을 고려해 입력되는 데이터를 크게 스트리밍과 배치로볼 수 있다.  
나는 kinesis를 사용해본 경험이있는데 kinesis의 배치를 줄여서 스트리밍으로 생각하고있었는데 위에서 말하는 스트리밍에 대한 이해는 아직 부족하다
     
## 데이터의 가공 시스템
- ETL(Extract - transform -load)
- 원본 데이터를 가공해서 목적에 맞는 데이터를 생성
- 유효한 데이터를 판별 , drop/marking/transform
- 기술스택
  데이터의 전달에서 활용하는 도구들을 활용

이전에 해본 ETL (지금생각해보면 ETL스럽지도않음...)만을 DE로서 필요한 데이터의 가공이라고 생각했는데 ETL외에도 유효한 데이터를 판별해 데이터의 신뢰성을 올리는 작업 또한 아주 중요하다고 생각한다

## 데이터 분석 및 활용 시스템
- 분석가가 쉽게 활용할 수 있는 도구(SQL, Jupyter)를 이용해서 빠르게 데이터를 조회할 수 있는 시스템을 구축
- AI관련 엔지니어 또는 연구자가 활용할 수 있는 도구로 AI 로직을 태워볼 수 있는 환경 구축 (MLOps 관련)
- 빠르게 조회할 수 있는 환경을 구축
	- 빠르게 조회할 수 있는 데이터 저장소 API 서비스 개발
	- 빠르게 조회할 수 있는 데이터 베이스 데이터 적재
- 시스템, 서비스의 이상을 분석해서 판단
- 기술스택
  Elastic Search, Kibana, Hadoop, Hive, Jupyter, Spark, Presto, Druid

DE가 어떤목적으로 일을 하는지 결정된다고 볼 수 있다 이부분에서 해봤던것은 쿼리를 입력하면 API에서 제공해주는 것이니 빠르게 조회할 수 있는 환경을 구축 정도로 볼 수 있을 것이다.
아직 모르는부분이 많다
  
## 데이터 저장소
- DBA를 따로 두기 어려운 경우 DE에게 맡기는 경우
- DBA가 있어도 데이터 엔지니어가 데이터의 전달 가공 활용 시스템을 맡고 신뢰성을 보장할 수 있어야 한다.
- 데이터가 유실되지 않도록 보장
- 데이터 저장소를 안정적으로 이용할 수 있는 시스템
- 기술스택
  Elastic search, Hadoop

데이터의 신뢰성과 안정성이 무엇보다 중요하다.

## 데이터 엔지니어링의 목적은 무엇일까?  
데이터 엔지니어링은 데이터 기반 의사결정을 위한 인프라를 만드는 것으로   
비즈니스 의사결정으로는  
예를 들어 가격책정, 모니터링, 분석 등  
서비스 운영/개선으로는  
A/B테스트 UI/UX 운영/자동화 같은게 있다  

## 데이터 엔지니어링이 왜 필요할까?
분야를 막론하고 대부분의 기업들이 느끼는 데이터에 관한문제 때문이다.  
데이터 기반 의사 결정은 아주 강력하고 그렇기에 분석은 큰 힘이 된다.   
하지만 이 방대한 데이터를 다르고 사용하는 것은 쉽지않다.  
데이터를 이용해서 인사이트를 추출하는 업무의 대부분은 데이터 엔지니어링이기 때문이다.  

예전에 부트캠프를 할때 이런말이있었다.  
Garbage in garbage out  
복잡한 데이터 모델을 만드는 것보다 좋은 데이터를 모으고 잘 관리하는 것이 훨씬 효율적인 성과를 낸다.  
실제로 NLP 프로젝트를 할때 열심히 모델을 만들었지만 그 모델을 만들 때 사용한 데이터에 대한 신뢰도가 떨어지자 결과에 대해서도 신뢰도가 떨어지는 경험을 해 데이터 신뢰도의 중요성을 크게느낀적이있었다.  

## 모던 데이터 아키텍처

### 데이터 웨어하우스
과거
- 컴퓨터의 성능에 비해 비쌌다.
- 어느정도 용도가 정해져있었다.
- 데이터가 나올곳도 정해져있었다.

이렇게 적은 데이터와 정형된 데이터가 주를 이루어서 주로 RDB를 이용했다.  
처음 효율적인 데이터 모델링을 만드는게 중요했고 정형된 데이터이다보니 크게 변동이없었다.  
대부분의 데이터 처리도 ETL에 맞추어져있었다.  

현재
- 실시간성을 요구하는 기능들
- 빨라지는 기능추가
- 실시간 로그
- 비정형 데이터
- 서드파티데이터

데이터의 형태를 예측하기 힘들어 스키마를 정의하기 어려워졌다.  
또 컴퓨팅 파워가 저렴해져 최대한 많은 데이터를 저장하고 많은 양의 프로세싱을 할 수 있게되었다.  
컴퓨팅 파워에 대한 비용보다는 비즈니스와 속도를 최적화하는게 이득이다.  

기존에 ETL 방식이었다면 점점 ELT 방식으로 변환되고있다.  
기존에는 추출 변환  적재였다면  ELT는 추출하고 약간의정리를 통해 일단 저장한 후에 필요에 따라 변환하여 불러들인다.  


데이터 인프라 트랜드
- 클라우드 웨어하우스 - snowflake , google big query
- hadoop에서 databricks, presto같은 다음세대로
- 실시간 빅데이터 처리 (stream processing)
- ETL -> ELT
- Dataflow 자동화 (Airflow)
- 데이터 분석 팀을 두기보단 누구나 분석할 수 있도록
- 중앙화 되는 데이터 플랫폼 관리 (access control,data book)

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220823161626.png)


![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220823161651.png)

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220823161708.png)

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image//img/20220823161729.png)

일반적인 엔지니어링은 <mark style="background: #FF5582A6;">수집</mark> 및 <mark style="background: #FFB86CA6;">변환</mark> , <mark style="background: #FFF3A3A6;">데이터처리</mark> 에 집중한다.

앞으로 공부할 내용은
- spark 
  데이터 병령 - 분산 처리
- Airflow
  데이터 오케스트레이션
- kafka
  이벤트 스트리밍
- Flink
  분산 스트림 프로세싱
으로 아직 hadoop도 제대로 모르지만 순서대로 배울 시간이 부족하다. 
어떻게보면 좀 트렌드에 맞는 기술을 공부하면서 기초가 되는 부분을 공부하려고한다.

