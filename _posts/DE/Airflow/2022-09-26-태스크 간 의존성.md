---
published: true
layout: single
title: 태스크 간 의존성
categories: [Airflow]
tags:
  - task
toc: true
toc_sticky: true
date created: 월요일, 9월 26일 2022
date modified: 월요일, 9월 26일 2022
---

# 의존성
Task간의 의존하는지의 여부로 현재 Task는 의존하는 Task(업스트림)가 완료되지 않았다면 실행되지않는다.

의존성에는 크게 두가지 유형이있다.

## 선형 태스크
다음은 월병토끼이다.  
토끼하나 하나가 Task이고 편의상 순서대로 토끼 1~5라고했을때 어떤 의존성이있을까?

![700](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/%EC%84%A0%ED%98%95%EA%B5%AC%EC%A1%B0.gif)

``` python
#태스크간에 의존성 추가

토끼1>>>토끼2>>>토끼3>>>토끼4>>>토끼5
```

앞의 작업을 하는 토끼의 월병(결과물)이 다음 토끼의 월병(입력값)이되기 때문에 다음 작업으로 이동하기전에 작업이 완료되어야한다.  
이렇게 연속적으로 실행되는 작업을 선형체인 유형이라고한다.

## 팬인/팬아웃
다음도 월병 토끼이다.  
어떤 의존성이있을까?

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/bd59a098f201db25a63776e23d1c7c757dd81a2d.gif)

이전 월병토끼와 비슷하다

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/%EC%BB%B7.gif)  
이 토끼2를 잘보자  
다른 토끼들은 월병이 오기만하면 작업을하지만 토끼2는
1. <mark style="background: #FF5582A6;">앞 토끼의 작업이 끝나고</mark> 월병이 오는것
2. <mark style="background: #FFB86CA6;">흰색 소(안에넣는 앙금같은거)</mark>  
앞서 두가지 작업이 완료되어야지 작업을 시작한다.

이렇게 단일 다운스트림 태스크가 여러 업스트림 태스크에 의존성을 갖는 것을 <mark style="background: #FF5582A6;">팬인(다대일)</mark> 이라고 부른다.  
반대로 단일 업스트림 태스크가 여러 다운스트림 태스크에 의존성을 준다면 <mark style="background: #FFB86CA6;">팬아웃(일대다)</mark> 라고 한다.

``` python
[흰색 소,토끼1]>>토끼2>>토끼3>>토끼4>>토끼5
```

여러 태스크의 의존관계는 리스트를 표현하듯 대괄호로 묶어줄 수 있다.

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926200247.png)
- 스타트 더미 태스크를 사용하던데 왜 사용하는지 모르겠다.
- ~~소가 영어로 뭔지 모르겠어요~~

이제 다시한번 봅시다 팬인 구조가 보이나요?  
![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/bd59a098f201db25a63776e23d1c7c757dd81a2d.gif)

# 브랜치
![700](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/%EC%84%A0%ED%98%95%EA%B5%AC%EC%A1%B0.gif)  
다시 선형태스크의 월병 토끼입니다.  

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/ezgif.com-gif-maker%20(3).gif)  

내일부터 토끼3의 흰색 소의 양을 1.5배로 늘린다고 합니다.  
하지만 오늘까진 그대로 작업하고 내일부터 바꾸고싶은 상황입니다.  
바꿀수있는 방법은 두가지있습니다.

1. <mark style="background: #BBFABBA6;">토끼가 스스로 변경 (태스크 안에서 변경)</mark>
2. <mark style="background: #ADCCFFA6;">관리토끼가 변경 (DAG 내부에서 브랜치 )</mark>

어떤 방법이 되었든 토끼의작업은 흰색소가 1배, 1.5배 중 하나로 나누어지게되는데 이렇게 나누어지는 작업의 분기를 브랜치라는 개념으로 부릅니다. 브랜치는 서로 독립적이며 영향을 주지않습니다.

## 태스크 내에서 브랜치 (토끼가 스스로변경)
작업을 하는 토끼가 스스로 체크해서 작업을 변경합니다.

입력된 날짜가 조건날짜보다 전이면 1배  
아니면 1.5배를 주는 함수를 선택하게됩니다.

``` python
def _Rabbit3(**context):
    if context["execution_date"] < ERP_CHANGE_DATE:
        _Rabbit3_X100(**context)
    else :
        _Rabbit3_X150(**context)

Rabbit3 = PythonOperator(
						 task_id="Rabbit3",
						 dag=dag, 
						 python_callable = _Rabbit3
						 )
```

소를 1배든 1.5배든 이렇게 결과물이 호환되는 작업은 태스크내에서 수정이 가능하지만 아예 모양을 찍어내던가 반으로나눈다던가 결과물이 다른작업은 따로 태스크를 만드는게 좋습니다.


드디어 다음날이 되었고 흰색 소를 1.5배로 넣고있습니다.

![400](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/%EC%84%A0%ED%98%95%EA%B5%AC%EC%A1%B0.gif)  

그런데 작업을 하는 모습을 보니 이전과 별차이가 없어보입니다.

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926204859.png)

토끼가 작업내에서 작업을 변경하니까 제대로 변경이 되었는지 알수가 없는 문제 점이 생겼습니다.

## DAG 내부에서 브랜치 (관리토끼가 변경)
관리입장에서 제대로 바꿨는지 알기위해 ~~현실이라면 비효율적~~ 3번 토끼앞에 새로운 관리토끼(pick_rabbit)를 추가합니다.

이 관리토끼는 날짜만 보고 소를 1배 넣어야할지 1.5배 넣어야할지만 알려주는 토끼입니다.

``` python
def _pick_rabbit(**context):
    if context["execution_date"] < ERP_CHANGE_DATE:
        return "x100"
    else:
        return "x150"  

 pick_rabbit = BranchPythonOperator(
        task_id="pick_rabbit", 
        python_callable=_pick_rabbit)

```

BranchPythonOperator는 다음 작업의 ID를 반환해 다음작업의 분기를 선택하게됩니다.  
![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/ezgif.com-gif-maker%20(4).gif)  
이제 관리토끼(pick_rabbit)가 소를 얼마나 넣어야하는지 결정해줍니다.

``` python
    rabbit1 >> rabbit2 >> pick_rabbit
    pick_rabbit >> [x100, x150]
    [x100, x150] >> rabbit3
    rabbit3 >> rabbit4 >>rabbit5
```

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926211414.png)


![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926212440.png)

그런데 토끼3이 일을 하기위해선 이전 작업이 모두 완료되어야하는데 1배, 1.5배 둘중의 하나의 작업만 완료가 되기때문에 토끼3은 일을 하지 않는다. (실제로 동작시 스킵됩니다)

# 트리거 규칙
트리거 규칙은 태스크를 수행하기위한 조건이다.

위의 문제를 해결하기위해 트리거 규칙을 변경할 수 있다.  
기본적으로 airflow의 트리거 규칙은 <mark style="background: #FF5582A6;">all_success</mark> 로 전부 완료되어야지 다음 태스크가 동작한다.

<mark style="background: #FF5582A6;">none_failed</mark> 이라는 규칙은 업스트림 태스크가 실패하지않았다면 태스크를 실행하는 트리거 규칙이다.

``` python
    rabbit3 = DummyOperator(
			    task_id="rabbit3",
			    trigger_rule="none_failed")
```

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/ezgif.com-gif-maker%20(3).gif)  
앞의 작업에서 실패가 없으니 이제 토끼3은 일을한다.


선형체인에서는 브랜치를 나누고 none_failed로 충분히 가능하지만  
팬인 상황에서 none_failed를 사용하면 돌아가기는 하겠지만  
브랜치의 조건을 명확하게 하기위해 브랜치를 병합할수도있습니다.

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926213915.png)

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926213714.png)

## 조건부 태스크
airflow는 조건에따라 특정 태스크를 건너뛸 수 있는 다른 방법도 제공한다.

### 태스크 내에서 조건
``` python
def Rabbit5(**context):
	if 무엇인가 조건:
		무엇인가 행동()
```

태스크 내의 함수에 조건을 걸어서 태스크를 실행한다.  
사실상 아까전에 봤던 태스크 내에서 조건부로 브랜치를 선택하는것과 같다고 볼 수 있다.  
같다면 문제점 또한 같다.  
![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926222223.png)  
조건에 걸려 무엇인가 했던 아니면 안했던 결국 문제는 없었기때문에 success가 되어버리고 어떤행동이 되었는지 알수가 없다.

### 조건부 태스크 만들기
그래서 DAG에서도 눈으로 볼 수 있게 조건부 태스크를 만들 수 있다.

``` python
from airflow.exceptions import AirflowSkipException

def something(**context):
	if context["execution_date"] < ERP_CHANGE_DATE:
        raise AirflowSkipException("idk well something wrong")
```

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926223408.png)  
조건에 맞을 경우 정상적으로 작동하고

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926224745.png)  
조건에 맞지않을경우 조건부 태스크가 스킵되어 다음 태스크도 스킵이되어버린다.

### 내장 오퍼레이터 사용
가장 최근 실행한 DAG만 실행할때는 LastOnlyOperator를 사용할 수 있다.

``` python
from airflow.operators.latest_only import LatestOnlyOperator
...
latest_only = LatestOnlyOperator(task_id="latest_only", dag=dag)
...
[rabbit4,latest_only] >>rabbit5
```

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926225152.png)

### 추가적인 트리거 규칙
![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926225518.png)  
![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926225528.png)

# 태스크간 데이터 공유
airflow는 xcom을 사용해 태스크간에 작은 데이터를 공유 할 수 있다.

## xcom push와 pull을 사용
``` python
def _train_model(**context):
    model_id = str(uuid.uuid4())
    context["task_instance"].xcom_push(key="model_id", value=model_id)  

def _deploy_model(**context):
    model_id = context["task_instance"].xcom_pull(
        task_ids="train_model", key="model_id"
    )
    print(f"Deploying model {model_id}")
```

xcom_push로 데이터를 넣고  
![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926230309.png)  
xcom_pull로 데이터를 받아 올 수 있다.  
![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926230645.png)

## 템플릿에서 xcom사용
``` python
def _train_model(**context):
	model_id = str(uuid.uuid4())
	context["task_instance"].xcom_push(key="model_id", value=model_id)
	
def _deploy_model(templates_dict, **context):
	model_id = templates_dict["model_id"]
	print(f"Deploying model {model_id}")

deploy_model = PythonOperator(
	  task_id="deploy_model",
	  python_callable=_deploy_model,
	  templates_dict={
		  "model_id": "{{task_instance.xcom_pull(\
			  task_ids='train_model', \
			  key='model_id')}}"
},
)
```

## 리턴을 사용해 XCOM 기록
BashOperator에는 xcom_push 옵션으로 stdout에 기록된 마지막행을 XCOM값으로 기록할 수 있고  
PythonOperator에서는 리턴값을 Xcom으로 기록할 수 있다.

``` python
def _train_model(**context):
	model_id = str(uuid.uuid4())
	context["task_instance"].xcom_push(key="model_id", value=model_id)

####################

def _train_model(**context):
	model_id = str(uuid.uuid4())
	return model_id
```

이렇게 사용할 수 있다.

Xcom은 DAG에 표시되지않는다.  
또한 xcom에의한 보이지않는 의존성을 관리하기는 정말 힘들다.  
Xcom이 원자성을 무너뜨릴 수 있다 (??)  
Xcom이 저장하는 모든 값은 직렬화를 지원해야 한다는 기술적 한계  
Xcom 값의 저장 크기가 제한될 수 있다.

## 커스텀 XCOM 백엔드
왜 필요한지 모르겠음

# TaskFlow API
파이썬 태스크가 많은 DAG를 단순화 할 수 있다.

기존의 일반 코드

``` python
import uuid
import airflow
from airflow import DAG
from airflow.operators.dummy import DummyOperator
from airflow.operators.python import PythonOperator

def _train_model(**context):
    model_id = str(uuid.uuid4())
    context["task_instance"].xcom_push(key="model_id", value=model_id)

def _deploy_model(**context):
    model_id = context["task_instance"].xcom_pull(
        task_ids="train_model", key="model_id"
    )
    print(f"Deploying model {model_id}")

with DAG(
    dag_id="xcoms",
    start_date=airflow.utils.dates.days_ago(3),
    schedule_interval="@daily",
) as dag:
    start = DummyOperator(task_id="start")
    fetch_sales = DummyOperator(task_id="fetch_sales")
    clean_sales = DummyOperator(task_id="clean_sales")
    fetch_weather = DummyOperator(task_id="fetch_weather")
    clean_weather = DummyOperator(task_id="clean_weather")
    join_datasets = DummyOperator(task_id="join_datasets")
    train_model = PythonOperator(task_id="train_model", python_callable=_train_model)
    deploy_model = PythonOperator(task_id="deploy_model", python_callable=_deploy_model)  

    start >> [fetch_sales, fetch_weather]
    fetch_sales >> clean_sales
    fetch_weather >> clean_weather
    [clean_sales, clean_weather] >> join_datasets
    join_datasets >> train_model >> deploy_model
```

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926233210.png)

``` python
import uuid
import airflow
from airflow import DAG
from airflow.decorators import task
from airflow.operators.dummy import DummyOperator

with DAG(
    dag_id="taskflow_full",
    start_date=airflow.utils.dates.days_ago(3),
    schedule_interval="@daily",
) as dag:
    start = DummyOperator(task_id="start") 
    fetch_sales = DummyOperator(task_id="fetch_sales")
    clean_sales = DummyOperator(task_id="clean_sales")  
    fetch_weather = DummyOperator(task_id="fetch_weather")
    clean_weather = DummyOperator(task_id="clean_weather")
    join_datasets = DummyOperator(task_id="join_datasets")

    start >> [fetch_sales, fetch_weather]
    fetch_sales >> clean_sales
    fetch_weather >> clean_weather
    [clean_sales, clean_weather] >> join_datasets

    @task
    def train_model():
        model_id = str(uuid.uuid4())
        return model_id
        
    @task
    def deploy_model(model_id: str):
        print(f"Deploying model {model_id}")

    model_id = train_model()
    deploy_model(model_id)
    join_datasets >> model_id
```

![](https://raw.githubusercontent.com/Cloudblack/Forpicture/image/img/20220926233240.png)


- XCOM문제점인 태스크 간 의존성을 확인하지 못하는 문제를 taskflow API에서는 해당 함수내의 태스크간의 의존성을 숨기지않고 태스크간의 값을 명시적으로 전달함으로써 해결할 수 있습니다.

## 문제점
  PythonOperator만 구현되어있다. 다른 오퍼레이터와 섞어쓰면 복잡하다
